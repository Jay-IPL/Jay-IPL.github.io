
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-WF7TK7ED9N"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-WF7TK7ED9N');
</script>

<link rel="shortcut icon" type="image/x-icon" href="teasers/headshot_jiemei.jpg" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  
<title>Jie(Jay) Mei</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="js/hidebib.js"></script>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-40545479-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>


</head>

<body>
  <div class="container">
    <table width="900" border="0" align="center" cellpadding="20">
      <table width="90%" align="center" border="0" cellpadding="10">
        <tr>
          <td width="70%" valign="top">
            <p align="center">&nbsp;</p>

            <p align="center"><font size="6px">Jie(Jay) Mei</font><br>
            jiemei@uw.edu</p>

              <p style="font-size:16px;text-align:justify; text-justify:inter-ideograph;"> I am a fourth-year Ph.D. from the <a href="https://ipl-uw.github.io/">Information Processing Lab</a> at the <a href="https://www.washington.edu//">University of Washington, Seattle </a>
                where I am advised by Prof. <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>. My research involves deep learning, lifelong learning, multimodal learning (vision+language), and 3D vision.
                </p>



              <p style="font-size:16px;text-align:justify; text-justify:inter-ideograph;"> I just finished a vison language pre-training project as a research intern at <a href="https://research.google/teams/brain/">Google Brain</a>.
                  In 2022 summer, I was a research scientist intern in MapsCV team, <a href="https://about.meta.com/realitylabs/">Reality Labs</a>, at <a href="https://en.wikipedia.org/wiki/Meta_Platforms">Meta Platforms, Inc.</a>,
                  working on panoptic segmentation of Lidar Point Clouds. I was also a software engineer intern in
                  <a href="https://en.megvii.com/">Megvii, China</a> in 2019 summer, working on few-shot objects detection.
              </p>

              <p style="font-size:16px;text-align:justify; text-justify:inter-ideograph;">
                Prior to PhD study, I was advised by Distinguished Prof. <a href="https://en.wikipedia.org/wiki/Demetri_Terzopoulos">Demetri Terzopoulos</a>
                during the <a href="https://csst.ucla.edu/#:~:text=DESCRIPTION,interviews%20conducted%20by%20UCLA%20professors">UCLA CSST program</a>.
                  During my undergraduate, I am the recipient of the highest honor, <a href="http://www.bit.edu.cn/xww/zhxw/jxky1/a149421.htm"> Principal 'Teli Xu' Scholarship</a>,
                  in <a href="https://english.bit.edu.cn/">Beijing Institue of Technology</a>.
                  I was also advised by Prof. <a href="https://scholar.google.com.sg/citations?hl=zh-CN&user=RgzLZZsAAAAJ&view_op=list_works">Shengjin Wang</a>
                  from <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>.
              </p>

            <p> <a href="https://docs.google.com/document/d/1LzHCXEkK-yj8gVCapbJUYzcKYWApojmKT3Cx85J8qMo/edit?usp=sharing"><img src="icons/cv.png" height="16"></a> /
<!--            	<a href="https://twitter.com/georgiagkioxari"><img src="icons/twitter.png" height="16"></a> /-->
                <a href="https://www.linkedin.com/in/jie-jay-mei-59043b212/" target="_blank" ><img src="icons/linkedin.png" height="16"></a> /
                <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&hl=en&user=1BVToFAAAAAJ" target="_blank"><img src="icons/google_scholar.png" height="16"></a>
<!--                <a href="https://github.com/Jay-IPL" target="_blank" ><img src="icons/github_alt.png" height="16"></a>-->
            </p>
          </td>
          <td width="30%">
            <div class="instructorphoto">
                <img  src="teasers/headshot_jiemei.jpg" />
<!--              <img onmouseover="document.getElementById('georgia').src='teasers/me_in_crazy.JPG';"-->
<!--              onmouseout="document.getElementById('georgia').src='teasers/me_at_ark.jpeg';"src="teasers/me_at_ark.jpeg" id="georgia">-->
            </div>
          </td>
        </tr>
      </table>
    </table>
  </div>
  <br>

  <div class="container">
    <table width="90%" border="0" align="center" cellpadding="20">
    <h2>News</h2>
      <div class="news">
        <ul>
            <li><strong>[06/12/2023] </strong><span> Will start deep learning research internship at <a href="https://machinelearning.apple.com/">Apple</a>! </span></li>
            <li><strong>[09/26/2022] </strong><span> Start research internship at <a href="https://research.google/teams/brain/">Google Brain</a>! </span></li>
            <li><strong>[06/13/2022] </strong><span> Start research scientist internship at <a href="https://en.wikipedia.org/wiki/Meta_Platforms">Meta Platforms, Inc.</a>! </span></li>
            <li><strong>[06/10/2022] </strong><span> Pass the Ph.D. General Exam! &#127867;</span></li>
            <li><strong>[06/14/2021] </strong><span> Pass the Ph.D. Qualifying Exam! &#127867;</span></li>
            <li><strong>[06/19/2021] </strong><span> Our team's <a href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Yang_Long-Tailed_Recognition_of_SAR_Aerial_View_Objects_by_Cascading_and_CVPRW_2021_paper.pdf">work</a>
                wins the Honorable Mention <a href="teasers/NTIRE%20Award.pdf">Award</a> in <a href=https://data.vision.ee.ethz.ch/cvl/ntire21/>CVPR 2021 NTIRE Challenge</a>!</span></li>
            <li><strong>[09/20/2021] </strong><span> The <a href="https://arxiv.org/pdf/2102.03520.pdf">Hierarchical Classification</a> work is selected to present at <a href="https://wfc2021.com.au/">World Fisheries Congress 2021</a>!</span></li>
            <li><strong>[10/08/2021] </strong><span> Our team's <a href="BMTT2021_Track1_KITTI.pdf">work</a> on <a href="certificates-1.pdf">KITTI</a>, and <a href="BMTT2021_Track1_MOT.pdf">work</a> on <a href="certificates-3.pdf">MOT</a> wins the 1st place in <a href='http://cvlibs.net/datasets/kitti/eval_step.php'>Video Track</a> in the 6th Workshop on <a href="https://motchallenge.net/workshops/bmtt2021/">Benchmarking Multi-Target Tracking</a>, ICCV 2021.&#127867 </span></li>


        </ul>
      </div>
    </table>
  </div>
  <br>

  <div class="container">
    <h2> Work Experience </h2>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20" id="experience">
      <tr>
        <td>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5" style="padding-left: 20px;">
      <tr>

        <td width="12.5%" style="text-align: center;"><img src="teasers/apple.png" alt="msft_logo" width="44" height="52" valign="center"></td>
        <td width="12.5%" style="text-align: left;"> <span style="color:#1772d0; font-weight:bold"> <a href="https://machinelearning.apple.com/">Vision Team</a></span></td>
        <td width="12.5%" style="text-align: left;"> Deep Learning Research Intern</td>
        <td width="12.5%"> <em>(Jun, 2023 - Sep, 2023)</em></td>
        <!--<td rowspan="2"><img src="images/ms_logo.png" alt="ms_logo" width="50" height="60" valign="center"></td>-->
      </tr>
      <tr>

        <td width="12.5%" style="text-align: center;"><img src="teasers/google.png" alt="msft_logo" width="162" height="105" valign="center"></td>
          <td style="text-align: left;"> <span style="color:#1772d0; font-weight:bold"><a href="https://research.google/teams/brain/">Vision and Language Team, Google Brain</a></span></td>
        <td style="text-align: left;"> Research Intern + Part-time <br> Student Researcher</td>
        <td> <em>(Sep, 2022 - Apr, 2023)</em></td>
        <!--<td rowspan="2"><img src="images/ms_logo.png" alt="ms_logo" width="50" height="60" valign="center"></td>-->
      </tr>
      <tr>

        <td width="12.5%" style="text-align: center;"><img src="teasers/meta.png" alt="msft_logo" width="90" height="65" valign="center"></td>
          <td style="text-align: left;"> <span style="color:#1772d0; font-weight:bold"><a href="https://about.meta.com/realitylabs/">Maps CV Team, Reality Lab</a></span></td>
        <td style="text-align: left;"> Research Scientist Intern</td>
        <td> <em>(Jun, 2022 - Sep, 2022)</em></td>
        <!--<td rowspan="2"><img src="images/ms_logo.png" alt="ms_logo" width="50" height="60" valign="center"></td>-->
      </tr>

      <tr>

        <td width="12.5%" style="text-align: center;"><img src="teasers/megvii.png" alt="msft_logo" width="105" height="74" valign="center"></td>
          <td style="text-align: left;"> <span style="color:#1772d0; font-weight:bold"><a href="https://en.megvii.com/">Image and Video Group</a></span></td>
        <td style="text-align: left;"> Software Engineer Intern</td>
        <td> <em>(Jun, 2019 - Sep, 2019)</em></td>
        <!--<td rowspan="2"><img src="images/ms_logo.png" alt="ms_logo" width="50" height="60" valign="center"></td>-->
      </tr>



      </table>
  </div>
  <br>


  <div class="container">
    <h2> Research </h2>

       <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="100%" valign="center"><img src="teasers/mem.png" alt="game" width="160" height="160" style="border-style: none" alt="game" width="90" height="60" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2202.13018"><b>HCIL: Hierarchical Class Incremental Learning for Longline Fishing Visual Monitoring</b></a><br>
                        <strong>Jie Mei </strong>,
              Suzanne Romain,
              Craig Rose,
              Kelsey Magran,
              <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>
              <br>
          <em>IEEE International Conference on Image Processing (ICIP)</em>, 2022<br>

          <p>"This work introduces a Hierarchical Class Incremental Learning (HCIL) model, which significantly improves the state-of-the-art hierarchical classification methods under the CIL scenario."</p>

          <div a class="paper" id="HCIL">
            <a href="https://arxiv.org/abs/2202.13018">arxiv</a>/
<!--            <a href="https://arxiv.org/abs/2201.09373">code</a> /-->
<!--            <a href="http://www.robots.ox.ac.uk/~ow/synsin.html">project page</a> /-->
             <a href="https://www.youtube.com/watch?v=IxdNLaq5d08"> video </a>/
            <a shape="rect" href="javascript:togglebib('HCIL')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@misc{mei2022hcil,
      title={HCIL: Hierarchical Class Incremental Learning for Longline Fishing Visual Monitoring},
      author={Jie Mei and Suzanne Romain and Craig Rose and Kelsey Magrane and Jenq-Neng Hwang},
      year={2022},
      eprint={2202.13018},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
                 </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>






      <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="100%" valign="center"><img src="teasers/3d_fish.gif" alt="game" width="160" height="120" style="border-style: none" alt="game" width="90" height="60" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/abs/2201.09373"><b>Unsupervised Severely Deformed Mesh Reconstruction (DMR) from a Single-View Image</b></a><br>
                        <strong>Jie Mei </strong>,
              Jingxi Yu,
              Suzanne Romain,
              Craig Rose,
              Kelsey Magran,
              Graeme LeeSon,
              <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>
              <br>
          <em>IEEE International Conference on Multiedia and Expo (ICME)</em>, 2022<br>

          <p>"This paper proposes an unsupervised mesh reconstruction method for severely deformed objects from a single-view image."</p>

          <div a class="paper" id="dmr">
            <a href="https://arxiv.org/abs/2201.09373">arxiv</a>/
<!--            <a href="https://arxiv.org/abs/2201.09373">code</a> /-->
<!--            <a href="http://www.robots.ox.ac.uk/~ow/synsin.html">project page</a> /-->
<!--            video (soon)/-->
            <a shape="rect" href="javascript:togglebib('dmr')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@misc{mei2022unsupervised,
      title={Unsupervised Severely Deformed Mesh Reconstruction (DMR) from a Single-View Image},
      author={Jie Mei and Jingxi Yu and Suzanne Romain and Craig Rose and Kelsey Magrane and Graeme LeeSon and Jenq-Neng Hwang},
      year={2022},
      eprint={2201.09373},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
                 </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>



      <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="100%" valign="center"><img src="teasers/BMTT.gif" alt="game" width="170" height="80" style="border-style: none" alt="game" width="90" height="30" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://jay-ipl.github.io/"><b>Instance Tracking and Semantic Segmentation</b></a><br>
                        Haotian Zhang,
              Yizhou Wang,
              <strong>Jie Mei </strong>,
              Cheng-Yen Yang,
              Jiarui Cai,
              <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>
              <br>
          <em>International Conference on Computer Vision (ICCV) Workshop </em>, 2021<br>

          <p>"This work achieved No.1 place in ICCV 2021 BMTT Challenge."</p>

          <div class="paper" id="bmtt">
            <a href="https://motchallenge.net/workshops/bmtt2021/reports/kitti_uw_etri.pdf">arxiv (KITTI)</a> /
              <a href="https://motchallenge.net/workshops/bmtt2021/reports/motcha_uw_etri.pdf">arxiv (MOT)</a> /
<!--            <a href="https://github.com/facebookresearch/synsin">code</a> /-->
<!--            <a href="http://www.robots.ox.ac.uk/~ow/synsin.html">project page</a> /-->
<!--            <a href="https://www.youtube.com/watch?v=lKBs_xT9os4">video</a> /-->
            <a shape="rect" href="javascript:togglebib('bmtt')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@article{wanghvps,
  title={HVPS: A Human Video Panoptic Segmentation Framework},
  author={Wang, Yizhou and Zhang, Haotian and Jiang, Zhongyu and Mei, Jie and Yang, Cheng-Yen and Cai, Jiarui and Hwang, Jenq-Neng and Kim, Kwang-Ju and Kim, Pyong-Kun}
}
@article{zhangu3d,
  title={U3D-MOLTS: Unified 3D Monocular Object Localization, Tracking and Segmentation},
  author={Zhang, Haotian and Wang, Yizhou and Jiang, Zhongyu and Yang, Cheng-Yen and Mei, Jie and Cai, Jiarui and Hwang, Jenq-Neng and Kim, Kwang-Ju and Kim, Pyong-Kun}
}
            </pre>

          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>



      <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="100%" valign="center"><img src="teasers/fish_3d.gif" alt="game" width="160" height="120" style="border-style: none" alt="game" width="90" height="60" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2102.04639.pdf"><b>Absolute 3D Pose Estimation and Length Measurement of Severely Deformed Fish from Monocular Videos in Longline Fishing</b></a><br>
                        <strong>Jie Mei </strong>,
              <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>,
              Suzanne Romain,
              Craig Rose,
              Braden Moore,
              Kelsey Magrane
              <br>
          <em>The international Conference on Acoustics, Speech, & Signal Processing (ICASSP)</em>, 2021<br>

          <p>"This video-based method estimates the absolute 3D fish pose and fish length only from
                single-view 2D segmentation masks."</p>

          <div class="paper" id="A3d">
            <a href="https://arxiv.org/pdf/2102.04639.pdf">arxiv</a> /
<!--            <a href="https://github.com/facebookresearch/synsin">code</a> /-->
<!--            <a href="http://www.robots.ox.ac.uk/~ow/synsin.html">project page</a> /-->
            <a href="https://www.youtube.com/watch?v=lKBs_xT9os4">video</a> /
            <a shape="rect" href="javascript:togglebib('A3d')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{mei2021absolute,
  title={Absolute 3d Pose Estimation and Length Measurement of Severely Deformed Fish from Monocular Videos in Longline Fishing},
  author={Mei, Jie and Hwang, Jenq-Neng and Romain, Suzanne and Rose, Craig and Moore, Braden and Magrane, Kelsey},
  booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={2175--2179},
  year={2021},
  organization={IEEE}
}
            </pre>
          </div>
        </td>
        </td>
      </table>
    </div>
    <hr>




    <div class="publication">
      <table width="900" align="center" border="0" cellpadding="0">
        <td width="100%" valign="center"><img src="teasers/data%20tree.png" alt="game" width="190" height="110" style="border-style: none">
        <td width="60%" valign="top">
          <p><a href="https://arxiv.org/pdf/2102.03520.pdf"><b>Video-based Hierarchical Species Classification for Longline Fishing Monitoring</b></a><br>
          <strong>Jie Mei </strong>,
              <a href="https://people.ece.uw.edu/hwang/">Jenq-Neng Hwang</a>,
              Suzanne Romain,
              Craig Rose,
              Braden Moore,
              Kelsey Magrane
              <br>
          <em>International Conference on Pattern Recognitiong (ICPR)</em>, 2020<br>
          <p>"This paper proposes a hierarchical classification dataset and a method enforcing the hierarchical data structure.
          It also introduces an efficient training and inference strategy for video-based fisheries data classification."</p>

          
          <div class="paper" id="HSC">
<!--            <a href="https://ai.facebook.com/blog/-introducing-pytorch3d-an-open-source-library-for-3d-deep-learning/">blog</a> /-->
            <a href="https://arxiv.org/pdf/2102.03520.pdf">arxiv</a> /
<!--            <a href="https://github.com/facebookresearch/pytorch3d">code</a> /-->
<!--            <a href="https://pytorch3d.org/">project page</a> /-->
            <a href="https://www.youtube.com/watch?v=YGV62bahQq4&t=8s">video</a> /
            <a shape="rect" href="javascript:togglebib('HSC')" class="togglebib">bibtex</a>
            <pre xml:space="preserve">
@inproceedings{Mei2020VideobasedHS,
  title={Video-based Hierarchical Species Classification for Longline Fishing Monitoring},
  author={J. Mei and Jenq-Neng Hwang and S. Romain and Craig S. Rose and Braden Moore and Kelsey Magrane},
  booktitle={ICPR Workshops},
  year={2020}
}
            </pre>   
          </div>
        </td> 
        </td>
      </table>
    </div>
<!--    <hr>-->






<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/visiontouch.png" alt="game" width="180" height="80" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/2007.03778.pdf"><b>3D Shape Reconstruction from Vision and Touch</b></a><br>-->
<!--          <a href="https://edwardsmith1884.github.io/">Edward J. Smith</a>, <a href="https://www.robertocalandra.com/about/">Roberto Calandra</a>, <a href="https://sites.google.com/site/adriromsor/home">Adriana Romero</a>, <strong>Georgia Gkioxari</strong>, <a href="https://mila.quebec/en/person/david-meger/">David Meger</a>, <a href="https://people.eecs.berkeley.edu/~malik/"> Jitendra Malik</a>, <a href="https://www.linkedin.com/in/michal-drozdzal-a36b9b42/?originalSubdomain=ca">Michal Drozdal</a> <br>-->
<!--          <em>Conference on Neural Information Processing Systems (NeurIPS)</em>, 2020 <br>-->

<!--          <div class="paper" id="visiontouch">-->
<!--            <a href="https://arxiv.org/abs/2007.03778">arxiv</a> /-->
<!--            <a href="https://github.com/facebookresearch/3D-Vision-and-Touch">code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('visiontouch')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{smith20203d,-->
<!--  title={3D Shape Reconstruction from Vision and Touch},-->
<!--  author={Smith, Edward J and Calandra, Roberto and Romero, Adriana and Gkioxari,-->
<!--          Georgia and Meger, David and Malik, Jitendra and Drozdzal, Michal},-->
<!--  journal={NeurIPS},-->
<!--  year={2020}-->
<!--}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->



<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/meshrcnn.gif" alt="game" width="190" height="110" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1906.02739.pdf"><b>Mesh R-CNN</b></a><br>-->
<!--          <strong> Georgia Gkioxari</strong>, <a href="https://people.eecs.berkeley.edu/~malik/"> Jitendra Malik</a>, <a href="https://cs.stanford.edu/people/jcjohns/"> Justin Johnson</a><br>-->
<!--          <em>International Conference of Computer Vision (ICCV)</em>, 2019 <br>-->

<!--          <div class="paper" id="meshrcnn">-->
<!--            <a href="https://arxiv.org/abs/1906.02739">arxiv</a> /-->
<!--            <a href="https://github.com/facebookresearch/meshrcnn">code</a> /-->
<!--            <a href="meshrcnn/index.html">project page</a> /-->
<!--            <a href="https://docs.google.com/presentation/d/18yd22C2RCs_dACrRL01r1eqHq9FrGwPXQAokq6QqSjE/edit?usp=sharing">examples</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('meshrcnn')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{meshrcnn,-->
<!--Title={Mesh R-CNN},-->
<!--Author={Georgia Gkioxari, Jitendra Malik, Justin Johnson},-->
<!--Journal={ICCV},-->
<!--Year={2019}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="https://wijmans.xyz/img/eqa-matter-tease.png" alt="game" width="190" height="150" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1904.03461.pdf"><b>Embodied Question Answering in Photorealistic Environments with Point Cloud Perception</b></a><br>-->
<!--          <a href="https://wijmans.xyz/">Erik Wijmans</a>, <a href="http://samyak-268.github.io/"> Samyak Datta</a>, <a href="https://research.fb.com/people/maksymets-oleksandr/"> Oleksandr Maksymets</a>, <a href="http://abhishekdas.com/"> Abhishek Das</a>, <strong> Georgia Gkioxari</strong>, <a href="https://www.cc.gatech.edu/~slee3191/"> Stefan Lee</a>, <a href="http://prof.irfanessa.com/"> Irfan Essa</a>, <a href="https://www.cc.gatech.edu/~parikh/"> Devi Parikh</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019 <strong>(oral)</strong><br>-->

<!--          <div class="paper" id="matterport">-->
<!--            <a href="https://arxiv.org/abs/1904.03461">arxiv</a> /-->
<!--            <a href="http://embodiedqa.org/"> project page</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('matterport')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{wijmans2019,-->
<!--Title={Embodied Question Answering in Photorealistic Environments with Point Cloud Perception},-->
<!--Author={Erik Wijmans and Samyak Datta and Oleksandr Maksymets and Georgia Gkioxari-->
<!--        and Stefan Lee and Irfan Essa and Devi Parikh and Dhruv Batra},-->
<!--Journal={CVPR},-->
<!--Year={2019}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/mteqa.png" alt="game" width="180" height="120" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1904.04686.pdf"><b>Multi-Target Embodied Question Answering</b></a><br>-->
<!--          <a href="http://www.cs.unc.edu/~licheng/">Licheng Yu</a>, <a href="http://xinleic.xyz/"> Xinlei Chen</a>, <strong> Georgia Gkioxari</strong>, <a href="http://www.cs.unc.edu/~mbansal/"> Mohit Bansal</a>, <a href="http://tamaraberg.com/"> Tamara Berg</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2019 <br>-->

<!--          <div class="paper" id="mteqa">-->
<!--            <a href="https://arxiv.org/abs/1904.04686">arxiv</a> /-->
<!--            <a href="http://embodiedqa.org/"> project page</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('mteqa')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{mteqa,-->
<!--Title={Multi-Target Embodied Question Answering},-->
<!--Author={Licheng Yu and Xinlei Chen and Georgia Gkioxari and Mohit Bansal and Tamara Berg and Dhruv Batra},-->
<!--Journal={CVPR},-->
<!--Year={2019}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/nmc.png" alt="game" width="180" height="140" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1810.11181.pdf"><b>Neural Modular Control for Embodied Question Answering</b></a><br>-->
<!--          <a href="http://abhishekdas.com/"> Abhishek Das</a>, <strong> Georgia Gkioxari</strong>, <a href="https://www.cc.gatech.edu/~slee3191/"> Stefan Lee</a>, <a href="https://www.cc.gatech.edu/~parikh/"> Devi Parikh</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>-->
<!--          <em>Conference on Robot Learning (CoRL)</em>, 2018<br>-->

<!--          <div class="paper" id="nmc">-->
<!--            <a href="https://arxiv.org/abs/1810.11181">arxiv</a> /-->
<!--            <a href="http://embodiedqa.org/"> project page</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('nmc')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{nmc,-->
<!--Title={{N}eural {M}odular {C}ontrol for {E}mbodied {Q}uestion {A}nswering},-->
<!--Author={Abhishek Das and Georgia Gkioxari-->
<!--        and Stefan Lee and Devi Parikh and Dhruv Batra},-->
<!--Journal={CoRL},-->
<!--Year={2018}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/house3D.gif" alt="game" width="180" height="140" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1801.02209.pdf"><b>Building Generalizable Agents With a Realistic And Rich 3D Environment</b></a><br>-->
<!--          <a href="https://jxwuyi.weebly.com/"> Yi Wu</a>, <a href="https://github.com/ppwwyyxx"> Yuxin Wu</a>, <strong>Georgia Gkioxari</strong>, <a href="http://yuandong-tian.com/"> Yuandong Tian</a><br>-->
<!--          <em>International Conference on Learning Representations (ICLR), Workshop Track</em>, 2018<br>-->

<!--          <div class="paper" id="house3D">-->
<!--            <a href="https://arxiv.org/abs/1801.02209">arxiv</a> /-->
<!--            <a href="https://github.com/facebookresearch/House3D"> code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('house3D')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{wu2018house3D,-->
<!--Author    = {Yi Wu and Yuxin Wu and-->
<!--            Georgia Gkioxari and Yuandong Tian},-->
<!--Title     = {Building Generalizable Agents With a Realistic And Rich 3D Environment},-->
<!--Journal   = {arXiv preprint arXiv:1801.02209},-->
<!--Year      = {2018}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/interactnet_teaser.png" alt="game" width="180" height="130" style="border-style: none">-->
<!--          <td width="60%" valign="top">-->
<!--            <p><a href="https://arxiv.org/pdf/1704.07333.pdf"><b>Detecting and Recognizing Human-Object Interactions</b></a><br>-->
<!--            <strong>Georgia Gkioxari</strong>,  <a href="http://www.rossgirshick.info/"> Ross Girshick</a>, <a href="https://pdollar.github.io/"> Piotr Doll&agraver</a> and <a href="http://kaiminghe.com/"> Kaiming He</a><br>-->
<!--            <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <strong>(spotlight)</strong><br>-->

<!--            <div class="paper" id="interactnet">-->
<!--              <a href="https://arxiv.org/abs/1704.07333">arxiv</a> /-->
<!--              <a href="InteractNet/index.html">project page</a> /-->
<!--              <a shape="rect" href="javascript:togglebib('interactnet')" class="togglebib">bibtex</a>-->
<!--              <pre xml:space="preserve">-->
<!--@article{gkioxari2017interactnet,-->
<!--Author    = {Georgia Gkioxari and Ross Girshick and-->
<!--             Piotr Doll\'{a}r and Kaiming He},-->
<!--Title     = {Detecting and Recognizing Human-Object Intaractions},-->
<!--Journal   = {CVPR},-->
<!--Year      = {2018}}-->
<!--              </pre>-->
<!--            </div>-->
<!--          </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/embodiedqa.gif" alt="game" width="180" height="130" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1711.11543.pdf"><b>Embodied Question Answering</b></a><br>-->
<!--          <a href="http://abhishekdas.com/"> Abhishek Das</a>, <a href="http://samyak-268.github.io/"> Samyak Datta</a>,<strong> Georgia Gkioxari</strong>, <a href="https://www.cc.gatech.edu/~slee3191/"> Stefan Lee</a>, <a href="https://www.cc.gatech.edu/~parikh/"> Devi Parikh</a>, <a href="https://www.cc.gatech.edu/~dbatra/"> Dhruv Batra</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <strong>(oral)</strong><br>-->

<!--          <div class="paper" id="embodiedqa">-->
<!--            <a href="https://arxiv.org/abs/1711.11543">arxiv</a> /-->
<!--            <a href="http://embodiedqa.org/"> project page</a> /-->
<!--            <a href="https://github.com/facebookresearch/EmbodiedQA"> code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('embodiedqa')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{embodiedqa,-->
<!--Title={{E}mbodied {Q}uestion {A}nswering},-->
<!--Author={Abhishek Das and Samyak Datta and-->
<!--          Georgia Gkioxari and Stefan Lee and-->
<!--          Devi Parikh and Dhruv Batra},-->
<!--Journal={CVPR},-->
<!--Year={2018}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/posetrack1.gif" alt="game" width="180" height="80" style="border-style: none" align="middle">-->
<!--        <img src="teasers/posetrack2.gif" alt="game" width="180" height="80" style="border-style: none" align="middle">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1712.09184.pdf"><b>Detect-and-Track: Efficient Pose Estimation in Videos</b></a><br>-->
<!--          <a href="http://rohitgirdhar.github.io/"> Rohit Girdhar</a>, <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.dartmouth.edu/~lorenzo/home.html"> Lorenzo Torresani</a>, <a href="https://research.fb.com/people/paluri-manohar/"> Manohar Paluri</a> and <a href="http://www.cs.dartmouth.edu/~dutran/"> Du Tran</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>-->

<!--          <div class="paper" id="posetrack">-->
<!--            <a href="https://arxiv.org/abs/1712.09184">arxiv</a> /-->
<!--            <a href="https://github.com/facebookresearch/DetectAndTrack/">code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('posetrack')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{girdhar2018,-->
<!--Title={Detect-and-Track: Efficient Pose Estimation in Videos,-->
<!--Author={Rohit Girdhar and Georgia Gkioxari and-->
<!--        Lorenzo Torresani and Manohar Paluri and Du Tran},-->
<!--Journal={CVPR},-->
<!--Year={2018}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/dd.png" alt="game" width="190" height="90" style="border-style: none" valign="middle">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1712.04440.pdf"><b>Data Distillation: Towards Omni-Supervised Learning</b></a><br>-->
<!--          Ilija Radosavovic, <a href="https://pdollar.github.io/"> Piotr Doll&agraver</a>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a>, <strong>Georgia Gkioxari</strong> and <a href="http://kaiminghe.com/"> Kaiming He</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2018 <br>-->

<!--          <div class="paper" id="datadistillation">-->
<!--            <a href="https://arxiv.org/abs/1712.04440">arxiv</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('datadistillation')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{dd,-->
<!--Title={Data Distillation: Towards Omni-Supervised Learning,-->
<!--Author={Ilija Radosavovic and Piotr Doll\'{a}r and-->
<!--        Ross Girshick and Georgia Gkioxari and-->
<!--        Kaiming He},-->
<!--Journal={CVPR},-->
<!--Year={2018}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/mrcnn_teaser.png" alt="game" width="180" height="140" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1703.06870.pdf"><b>Mask R-CNN</b></a><br>-->
<!--          <a href="http://kaiminghe.com/"> Kaiming He</a>, <strong>Georgia Gkioxari</strong>, <a href="https://pdollar.github.io/"> Piotr Doll&agraver</a> and <a href="http://www.rossgirshick.info/"> Ross Girshick</a><br>-->
<!--          <em>International Conference of Computer Vision (ICCV)</em>, 2017 <strong>(oral)</strong><br>-->
<!--          <mark>Best Paper Award (Marr Prize)</mark> &nbsp-->

<!--          <div class="paper" id="maskrcnn">-->
<!--            <a href="https://arxiv.org/abs/1703.06870">arxiv</a> /-->
<!--            <a href="https://github.com/facebookresearch/Detectron"> code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('maskrcnn')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{he2017maskrcnn,-->
<!--Author    = {Kaiming He and Georgia Gkioxari and-->
<!--         Piotr Doll\'{a}r and Ross Girshick},-->
<!--Title     = {Mask R-CNN},-->
<!--Journal   = {arXiv preprint arXiv:1703.06870},-->
<!--Year      = {2017}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/learn2smile.png" alt="game" width="180" height="140" style="border-style: none">-->
<!--          <td width="60%" valign="top">-->
<!--            <p><a href="https://www.dropbox.com/s/ljfnv3i1jw0uzbh/learn2smile-learning-verbal.pdf?dl=0"><b>Learn2Smile: Learning Non-verbal Interaction through Observation</b></a><br>-->
<!--            Will Feng, Anitha Kannan, <strong>Georgia Gkioxari</strong>, <a href="http://larryzitnick.org/"> Larry Zitnick</a><br>-->
<!--            <em>International Conference on Intelligent Robots and Systems (IROS)</em>, 2017 <strong>(oral)</strong><br>-->
<!--            <mark>Finalist for the JTCF Novel Technology Paper Award For Amusement Culture</mark> &nbsp-->

<!--            <div class="paper" id="learn2smile">-->
<!--              <a shape="rect" href="javascript:togglebib('learn2smile')" class="togglebib">bibtex</a>-->
<!--              <pre xml:space="preserve">-->
<!--@article{learn2smile2017,-->
<!--Author    = {Will Feng, Anitha Kannan, Georgia Gkioxari and Larry Zitnick},-->
<!--Title     = {Learn2Smile: Learning Non-verbal Interaction through Observation},-->
<!--Journal   = {IROS},-->
<!--Year      = {2017}}-->
<!--              </pre>-->
<!--            </div>-->
<!--          </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->


<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="ChainModels/out596.gif" alt="game" width="180" height="90" style="border-style: none" align="middle">-->
<!--        <img src="ChainModels/out2247.gif" alt="tennis" width="180" height="90" style="border-style: none" align="middle">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="http://arxiv.org/pdf/1605.02346v2.pdf"><b>Chained Predictions Using Convolutional Neural Networks</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong>, <a href="https://research.google.com/pubs/AlexanderToshev.html">Alexander Toshev</a> and <a href="http://www.cs.toronto.edu/~ndjaitly">Navdeep Jaitly</a><br>-->
<!--          <em>European Conference of Computer Vision (ECCV)</em>, 2016 &nbsp-->

<!--          <div class="paper" id="chain">-->
<!--            <a href="http://arxiv.org/abs/1605.02346">arxiv</a> /-->
<!--            <a href="ChainModels/index.html">project page</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('chain')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{chain16,-->
<!--Author = {G. Gkioxari and A. Toshev and N. Jaitly},-->
<!--Title = {Chained Predictions Using-->
<!--       Convolutional Neural Networks},-->
<!--Booktitle = {ECCV},-->
<!--Year = {2016}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/frstarcnn.png" alt="rstarcnn" width="180" height="160" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://arxiv.org/pdf/1505.01197.pdf"><b>Contextual Action Recognition with R*CNN</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->
<!--          <em>International Conference of Computer Vision (ICCV)</em>, 2015 &nbsp-->

<!--          <div class="paper" id="rstarcnn">-->
<!--            <a href="http://arxiv.org/abs/1505.01197">arxiv</a> /-->
<!--            <a href="https://github.com/gkioxari/RstarCNN">code</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('rstarcnn')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{rstarcnn,-->
<!--Author = {G. Gkioxari and R. Girshick and J. Malik},-->
<!--Title = {Contextual Action Recognition with R*CNN},-->
<!--Booktitle = {ICCV},-->
<!--Year = {2015}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><a href="deepparts.gif"><img src="teasers/deepparts.gif" alt="deepparts" width="180" height="110" style="border-style: none"></a>-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://www.dropbox.com/s/jovtmei1is10r05/deepparts_camera_ready.pdf?dl=0"><b>Actions and Attributes from Wholes and Parts</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->
<!--          <em>International Conference of Computer Vision (ICCV)</em>, 2015 &nbsp-->

<!--          <div class="paper" id="deepparts">-->
<!--            <a href="http://arxiv.org/abs/1412.2604">arxiv</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('deepparts')" class="togglebib">bibtex</a>-->
<!--            <pre xml:space="preserve">-->
<!--@article{deepparts,-->
<!--Author = {G. Gkioxari and R. Girshick and J. Malik},-->
<!--Title = {Actions and Attributes from Wholes and Parts},-->
<!--Booktitle = {ICCV},-->
<!--Year = {2015}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/fat.png" alt="fat" width="180" height="120" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://www.dropbox.com/s/jf9oukcm893e72g/action_tubes.pdf?dl=0"><b>Finding Action Tubes</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2015 &nbsp-->

<!--         <div class="paper" id="ActionCNN">-->
<!--            <a href="ActionTubes/index.html">project page</a> /-->
<!--            <a href="http://arxiv.org/abs/1411.6031">arxiv</a> /-->
<!--            <a href="https://github.com/gkioxari/ActionTubes">code</a> /-->
<!--            <a href="ActionTubes/NegativeResults.txt">negative results</a> /-->
<!--            <a href="http://nbviewer.ipython.org/github/gkioxari/ActionTubes/blob/master/test_tubes/UCFsports_benchmark/UCFsports_auc.ipynb">UCF Sports Benchmark</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('ActionCNN')" class="togglebib">bibtex</a></span>-->
<!--            <pre xml:space="preserve">-->
<!--@article{actiontubes,-->
<!--Author = {G. Gkioxari and J. Malik},-->
<!--Title = {Finding Action Tubes},-->
<!--Booktitle = {CVPR},-->
<!--Year = {2015}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/multiloss.png" alt="multiloss" width="180" height="120" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://www.dropbox.com/s/nv2o0hpdt9n8fak/multiloss.pdf?dl=0"><b>R-CNNs for Pose Estimation and Action Detection</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.berkeley.edu/~bharath2/">Bharath Hariharan</a>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->

<!--          <div class="paper" id="multiloss">-->
<!--            <a href="PersonNet/index.html">project page</a> /-->
<!--            <a href="http://arxiv.org/abs/1406.5212">arxiv</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('multiloss')" class="togglebib">bibtex</a></span>-->
<!--            <pre xml:space="preserve">-->
<!--@article{poseactionrcnn,-->
<!--Author = {G. Gkioxari and B. Hariharan-->
<!--    and R. Girshick and J. Malik},-->
<!--Title = {R-CNNs for Pose Estimation and Action Detection},-->
<!--ArchivePrefix = {arXiv},-->
<!--Eprint = {1406.5212},-->
<!--PrimaryClass = {cs.CV},-->
<!--Year = {2014}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/kposelets.png" alt="kposelets" width="180" height="120" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://www.dropbox.com/s/db88eb3i4hsl1a4/kposelets.pdf?dl=0"><b>Using k-poselets for detecting people and localizing their keypoints</b></a><br>-->
<!--          <strong>Georgia Gkioxari*</strong>, <a href="http://www.cs.berkeley.edu/~bharath2/">Bharath Hariharan*</a>, <a href="http://www.rossgirshick.info/"> Ross Girshick</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2014 &nbsp <br>-->
<!--         <strong> * authors contributed equally</strong>-->

<!--          <div class="paper" id="kposelets">-->
<!--            <a href="kposelets/index.html">project page</a> /-->
<!--            <a href="https://www.dropbox.com/s/jqveoqso6572av7/kposelets-release.tar.gz?dl=0">code</a> /-->
<!--            <a href="https://github.com/gkioxari/k-poselets">github</a> /-->
<!--            <a href="https://www.dropbox.com/s/0kn3f0mfudj9qk9/kposelets-spotlight.mp4?dl=0">spotlight</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('kposelets')" class="togglebib">bibtex</a></span>-->
<!--            <pre xml:space="preserve">-->
<!--@inproceedings{kposelets,-->
<!--Author = {G. Gkioxari and B. Hariharan-->
<!--      and R. Girshick and J. Malik},-->
<!--Title = {Using k-poselets for  detecting people and-->
<!--      localizing their keypoints},-->
<!--Booktitle = {CVPR},-->
<!--Year = {2014}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%" valign="center"><img src="teasers/armlets.png" alt="armlets" width="180" height="120" style="border-style: none">-->
<!--        <td width="60%" valign="top">-->
<!--          <p><a href="https://www.dropbox.com/s/r6vb6ace88hhrh9/GkioxariCVPR2013.pdf?dl=0"><b>Articulated Pose Estimation using Discriminative Armlet Classifiers</b></a><br>-->
<!--          <strong>Georgia Gkioxari</strong>, <a href="http://www.cs.berkeley.edu/~arbelaez/"> Pablo Arbelaez</a>, <a href="http://www.lubomir.org/"> Lubomir Bourdev</a> and <a href="http://www.cs.berkeley.edu/~malik/"> Jitendra Malik</a><br>-->
<!--          <em>Computer Vision and Pattern Recognition (CVPR)</em>, 2013 &nbsp-->

<!--          <div class="paper" id="armlets">-->
<!--            <a href="https://www.dropbox.com/s/bddbv8g5n427clt/armlets_slides.pptx?dl=0">slides</a> /-->
<!--            <a shape="rect" href="javascript:togglebib('armlets')" class="togglebib">bibtex</a></span>-->
<!--            <pre xml:space="preserve">-->
<!--@inproceedings{armlets,-->
<!--Author = {G. Gkioxari and P. Arbelaez-->
<!--      and L. Bourdev and J. Malik},-->
<!--Title  = {Articulated Pose Estimation using-->
<!--      Discriminative Armlet Classifiers},-->
<!--Booktitle = {CVPR},-->
<!--Year  = {2013}}-->
<!--            </pre>-->
<!--          </div>-->
<!--        </td>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->

      <p style="text-align:right;">Website Credits to <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>
  </div>
  <br>

<!--  <div class="container">-->
<!--    <h2> Teaching </h2>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%"><img src="teasers/pacman.png" alt="pacman" width="180" height="140"></td>-->
<!--        <td width="60%" valign="center">-->
<!--          <p>-->
<!--            <a href="http://inst.eecs.berkeley.edu/~cs188/fa11/announcements.html"><b>CS188 - Fall 2011 </a> (GSI -<a href="http://gsi.berkeley.edu/programs-services/award-programs/ogsi/ogsi-2012/"> GSI Outstanding Award</a>)</b><br>-->

<!--          </p>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <hr>-->

<!--    <div class="publication">-->
<!--      <table width="900" align="center" border="0" cellpadding="0">-->
<!--        <td width="40%"><img src="teasers/pipe_icon.jpg" alt="pipe" width="180" height="140"></td>-->
<!--        <td width="60%" valign="center">-->
<!--          <p>-->
<!--            <a><b>CS 280 - Fall 2012 </a>(GSI)</b><br>-->
<!--          </p>-->
<!--        </td>-->
<!--      </table>-->
<!--    </div>-->
<!--    <p style="text-align:right;">Stolen from <a href="https://gkioxari.github.io/">Georgia Gkioxari</a></p>-->

<!--  </div>-->
<!--  <br>-->


<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


          
</body>
</html>
